{
    "dataset": {

        "test_file": "/home/jogonba2/TWilBERT/corpora/examples/example_mlm.txt",
        "vocab_file": "/home/jogonba2/TWilBERT/weights/bert_large_twitter/vocab"
    },

    "representation": {

        "max_len_training": 128,
        "max_len_test": 128,
        "bucket_min_a": 5,
        "bucket_min_b": 5,
        "bucket_max_a": 45,
        "bucket_max_b": 45,
        "bucket_steps": 5
    },

    "model": {

        "factorize_embeddings": false,
        "cross_sharing": false,
        "embedding_size": 768,
        "hidden_size": 768,
        "n_encoders": 12,
        "n_heads": 12,
        "attention_size": 64,
        "input_dropout": 0.0,
        "output_dropout": 0.0,
        "initializer_range": 0.02,
        "pkm": false,
        "pkm_params": {
            "factorize_embeddings": false,
            "k_dim": 512,
            "memory_size": 256,
            "n_heads": 4,
            "knn": 32,
            "in_layers": [10],
            "input_dropout": 0.0,
            "output_dropout": 0.0,
            "batch_norm": true
        },

        "masked_lm": {

            "type": "span",
            "max_span": 3,
            "budget": 0.15,
            "probs": {
                "mask": 0.8,
                "random": 0.1,
                "keep": 0.1
             }
         },

         "rop": {
             "use_rop": true,
             "n_hidden": 0,
             "hidden_size": 512
          }
    },

    "test": {
        "path_load_weights": "/home/jogonba2/TWilBERT/weights/bert_large_twitter/weights.hdf5"
    }
}

